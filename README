# Sparkify song play aggregation

Sparkify currently stores song play instance data in log form in a series of json files on disc.
This instrumentation loads the song play records as well as the song records themselves (also in
json format on disc to begin with) into a postgres star schema

## Postgres

Both the default database name and postgres root user name are "postgres" instead of "student",
when attempting to compose testing utilities for the etl scripting this will need to be considered.

Connect locally thereto with ```psql postgresql://postgres:postgres@127.0.0.1/sparkifydb```

## ETL

The ETL process itself reads files off disc and loads them into the "sparkifydb" database within
the postgres instance. This ETL script set assumes that the data in the logs is non-conflicting,
meaning that although some missing data points may be missing, there will not be two records with
the same user ID mapping to two different values for user's first name.

#### Artists and songs

For song data, the ETL extracts both the artist's information and the song's information and inserts
them as records into postgres. Upon inspection of the data, artists can author many songs but sometimes
they are listed with missing info, so the etl fills in those missing attributes as best it can from
recurrences in the same record

## Constructing postgres database

1) Lay down or replace the schema and data with ```python(|3) create_tables.py```

2) Insert data with ```python(|3) etl.py``` (script set assumes the location of the logs to be in "./data/<etc>")

## Docker image

There's a docker image with the necessary instrumentation baked in (postgres, python 3)

1) Purge any images/containers with ```purge.sh```

2) Generate a new image with ```build.sh```

3) Fire up and get a bash session inside the container with ```run.sh```
